{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exploradrome project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1v0NXNeATggiraiqK9vLCodnle1VKy0S6",
      "authorship_tag": "ABX9TyOL12wgGWQZ8PJcP6cgXVfE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "17afd5dc9e7d4e2e8580f11297c03367": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_72f97e10a34443a98dc305d3116962d3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_dc3210df12ee495a8955874aca78de00",
              "IPY_MODEL_6a165358c6084fa1bef21a33f3abfbd8"
            ]
          }
        },
        "72f97e10a34443a98dc305d3116962d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dc3210df12ee495a8955874aca78de00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_130b4d7898eb45f2bc955396fc6a589c",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 87306240,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 87306240,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e704f687f97d46599cb2400b61e330f6"
          }
        },
        "6a165358c6084fa1bef21a33f3abfbd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_726daa873c214d0ea9ec87e37d4c17b1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 83.3M/83.3M [00:00&lt;00:00, 171MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_391ff75c4fb44a75a82ecaae6e0de4e1"
          }
        },
        "130b4d7898eb45f2bc955396fc6a589c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e704f687f97d46599cb2400b61e330f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "726daa873c214d0ea9ec87e37d4c17b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "391ff75c4fb44a75a82ecaae6e0de4e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jbmw94/plantnetSimplon/blob/master/Exploradrome_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPvkquT6S0L4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "3c7cf2f5-77bb-4962-9425-6bb500bc283e"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "from fastai.vision import *\n",
        "from fastai import *\n",
        "import matplotlib.pyplot as plt             \n",
        " \n",
        "import seaborn as sns\n",
        "import tensorflow as tf \n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.layers import Activation, Flatten, MaxPool2D, ReLU\n",
        "from keras.layers import Conv2D, BatchNormalization\n",
        "from tqdm import tqdm\n",
        "from sklearn.utils import shuffle   "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1l959u5lXyc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "outputId": "8efcb103-f526-4d77-871c-9ef495b811a0"
      },
      "source": [
        "#code pour connaitre le nombre d'image par catégorie\n",
        "\n",
        "import os\n",
        "pathFold1 = '/content/drive/My Drive/image coupe'\n",
        "listUnfold1 = os.listdir('/content/drive/My Drive/image coupe')\n",
        "for unfold2 in listUnfold1 :\n",
        "\n",
        "    pathUnfold2 = pathFold1 + '/'+ unfold2 # chemin accés au sous sous dossier, ex bateau\n",
        "    listImgToSlice = os.listdir(pathUnfold2) # liste des images d'un sous sous dossiers (tel que bateau) à couper\n",
        "    print(unfold2 , \" possede \", len(listImgToSlice), \" éléments.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "maison_slice  possede  1400  éléments.\n",
            "cygne_slice  possede  435  éléments.\n",
            "chat_slice  possede  1224  éléments.\n",
            "pont_slice  possede  889  éléments.\n",
            "tortue_slice  possede  901  éléments.\n",
            "montagne_slice  possede  468  éléments.\n",
            "bol_slice  possede  316  éléments.\n",
            "lapin_slice  possede  700  éléments.\n",
            "renard_slice  possede  972  éléments.\n",
            "marteau_slice  possede  564  éléments.\n",
            "coeur_slice  possede  349  éléments.\n",
            "bateau_slice  possede  6484  éléments.\n",
            "models  possede  3  éléments.\n",
            "output  possede  13  éléments.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsSdJsdfYA1P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "outputId": "05d355b7-812f-4f91-deee-fe7f2bfd88f1"
      },
      "source": [
        "#code pour connaitre le nombre d'image par catégorie\n",
        "\n",
        "import os\n",
        "pathFold1 = '/content/drive/My Drive/image coupe'\n",
        "listUnfold1 = os.listdir('/content/drive/My Drive/image coupe')\n",
        "for unfold2 in listUnfold1 :\n",
        "\n",
        "    pathUnfold2 = pathFold1 + '/'+ unfold2 # chemin accés au sous sous dossier, ex bateau\n",
        "    listImgToSlice = os.listdir(pathUnfold2) # liste des images d'un sous sous dossiers (tel que bateau) à couper\n",
        "    print(unfold2 , \" possede \", len(listImgToSlice), \" éléments.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "models  possede  3  éléments.\n",
            "maison_slice  possede  1400  éléments.\n",
            "cygne_slice  possede  435  éléments.\n",
            "chat_slice  possede  1224  éléments.\n",
            "pont_slice  possede  889  éléments.\n",
            "tortue_slice  possede  901  éléments.\n",
            "montagne_slice  possede  468  éléments.\n",
            "bol_slice  possede  316  éléments.\n",
            "lapin_slice  possede  700  éléments.\n",
            "renard_slice  possede  972  éléments.\n",
            "marteau_slice  possede  564  éléments.\n",
            "coeur_slice  possede  349  éléments.\n",
            "bateau_slice  possede  6484  éléments.\n",
            "output  possede  13  éléments.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-p0bw6eOUjs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "2a761860-104e-429a-f576-61a46c8da21e"
      },
      "source": [
        "list_bat = os.listdir('/content/drive/My Drive/image coupe/bateau_slice')\n",
        "list_bat[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'sliced_bateau_356_01_02.png'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-aGFy-dwol_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "outputId": "ad590f5c-7f0a-4147-f98a-27dbc3ed09e5"
      },
      "source": [
        "import glob, os\n",
        "import image_slicer\n",
        "os.chdir(\"./\")\n",
        "for file in glob.glob(\"*.jpg\"):\n",
        "    image_slicer.slice(file, 60)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-3d1d4229485f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mimage_slicer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"*.jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mimage_slicer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'image_slicer'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUya7PeHOAsv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "my_drive = \"/content/drive/My Drive\"\n",
        "list_drive = os.listdir(my_drive)\n",
        "for i in list_drive : \n",
        "  if os.path.isfile(my_drive+'/'+i) and '.' in i and i.split('.')[-1] == 'png':\n",
        "    os.remove(my_drive+'/'+i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXBn-cqXOTG8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T62nLhc57e_c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Liste des catégories d'images\n",
        "class_names = ['maison', 'cygne', 'chat', 'pont', 'tortue', 'montagne', 'bol', 'lapin', 'bateaux', 'renard', 'marteau','coeur' ]\n",
        "# Dico des Labels\n",
        "class_names_label = {class_name:i for i, class_name in enumerate(class_names)}\n",
        "size = (150,150)\n",
        "#Création d'une fonction load_data qui permet de générer les échantillons de Train et Test contenant les images \n",
        "#et leurs labels\n",
        "def load_data():\n",
        "    \n",
        "    #Chemin d'accès aux datasets seg_train seg_test - A MODIFIER\n",
        "    datasets = ['/content/drive/My Drive/image']\n",
        "    output = []\n",
        "    \n",
        "    # Parcours des datasets\n",
        "    for dataset in datasets:\n",
        "        # Création de 2 listes images et labels\n",
        "        # A COMPLETER\n",
        "        folder = \"../input/\" + dataset\n",
        "        images = []\n",
        "        labels = []  \n",
        "        \n",
        "        # Parcours des sous-dossiers de chaque dossier \n",
        "        for folder in os.listdir(dataset):\n",
        "            \n",
        "            #Récupération du label (0, 1, 2,...) associé au sous-dossier folder à partir de class_names_label\n",
        "            # A COMPLETER\n",
        "            label = class_names_label[folder]\n",
        "            \n",
        "            # Parcours de chaque image dans chaque sous-dossier\n",
        "            for file in tqdm((os.listdir(os.path.join(dataset, folder)))):\n",
        "                \n",
        "                # Récupération du chemin de l'image\n",
        "                img_path = os.path.join(os.path.join(dataset, folder), file)\n",
        "                \n",
        "                # Lecture de l'image avec Cv2\n",
        "                # A COMPLETER\n",
        "\n",
        "                curr_img = cv2.imread(img_path)\n",
        "                curr_img = cv2.resize(curr_img, size)\n",
        "                \n",
        "\n",
        "                # Ajout de image dans la listes images et labels\n",
        "                # A COMPLETER\n",
        "                images.append(curr_img)\n",
        "                labels.append(label)    \n",
        "                images, labels = shuffle(images, labels)\n",
        "        # Conversion des listes images et labels en numpy.array\n",
        "        # A COMPLETER\n",
        "        images = np.array(images, dtype = 'float32')\n",
        "        labels = np.array(labels, dtype = 'int32')\n",
        "                \n",
        "        # Ajout d'images et labels à la liste output\n",
        "        output.append((images, labels))\n",
        "\n",
        "    return output\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-ckQDYT1SLH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "21e18dad-4867-4d22-eb19-3b655c743e57"
      },
      "source": [
        "np.random.seed(42)\n",
        "data = ImageDataBunch.from_folder('/content/drive/My Drive/images nettoyées et labelisées (bis)', train=\".\", valid_pct=0.2,\n",
        "        ds_tfms=get_transforms(), size=224, num_workers=4).normalize(imagenet_stats)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9D9dQTn9eQk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai.widgets import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giSOs5p6Muah",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pu1IftcF9gVJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "77d1659d-db79-4205-b2f8-e72b6d5c3306"
      },
      "source": [
        "db = (ImageList.from_folder('/content/drive/My Drive/images nettoyées et labelisées (bis)')\n",
        "                   .split_none()\n",
        "                   .label_from_folder()\n",
        "                   .transform(get_transforms(), size=224)\n",
        "                   .databunch()\n",
        "     )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMnFORgV-H-I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106,
          "referenced_widgets": [
            "17afd5dc9e7d4e2e8580f11297c03367",
            "72f97e10a34443a98dc305d3116962d3",
            "dc3210df12ee495a8955874aca78de00",
            "6a165358c6084fa1bef21a33f3abfbd8",
            "130b4d7898eb45f2bc955396fc6a589c",
            "e704f687f97d46599cb2400b61e330f6",
            "726daa873c214d0ea9ec87e37d4c17b1",
            "391ff75c4fb44a75a82ecaae6e0de4e1"
          ]
        },
        "outputId": "7f9b20da-44e2-43ba-bae6-ef59bde415ea"
      },
      "source": [
        "learn_cln = cnn_learner(db, models.resnet34, metrics=error_rate)\n",
        "\n",
        "learn_cln.save('stage-1')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet34-333f7ec4.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-333f7ec4.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "17afd5dc9e7d4e2e8580f11297c03367",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=87306240.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykVlfpyC9NOQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "outputId": "be3ba8a7-8144-4a8d-f225-9327282fcdd5"
      },
      "source": [
        "!pip install skorch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting skorch\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/c7/2f6434f9360c91a4bf14ae85f634758e5dacd3539cca4266a60be9f881ae/skorch-0.9.0-py3-none-any.whl (125kB)\n",
            "\r\u001b[K     |██▋                             | 10kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 20kB 2.2MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 30kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 40kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 51kB 2.5MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 61kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 71kB 3.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 81kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 92kB 3.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 102kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 112kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 122kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 3.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.6/dist-packages (from skorch) (0.8.7)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from skorch) (0.22.2.post1)\n",
            "Requirement already satisfied: tqdm>=4.14.0 in /usr/local/lib/python3.6/dist-packages (from skorch) (4.41.1)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from skorch) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from skorch) (1.18.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.19.1->skorch) (0.16.0)\n",
            "Installing collected packages: skorch\n",
            "Successfully installed skorch-0.9.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vprrdPweB73B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import random\n",
        "import datetime\n",
        "\n",
        "import matplotlib.cm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy\n",
        "import skimage.exposure\n",
        "import sklearn\n",
        "import sklearn.metrics\n",
        "import sklearn.metrics\n",
        "import sklearn.preprocessing\n",
        "import skorch.helper\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils\n",
        "import torchvision\n",
        "import tqdm\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLFpQCrfNIoV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_weights(m):\n",
        "    if type(m) == nn.Conv2d:\n",
        "        torch.nn.init.kaiming_uniform_(m.weight, nonlinearity=\"relu\")\n",
        "        m.bias.data.fill_(0.1)\n",
        "    if type(m) == nn.Linear:\n",
        "        # apply a uniform distribution to the weights and a bias=0\n",
        "        torch.nn.init.kaiming_uniform_(m.weight, nonlinearity=\"relu\")\n",
        "        m.bias.data.fill_(0.1)\n",
        "\n",
        "\n",
        "def init_weights_tl(m):\n",
        "    # if type(m) == nn.Conv2d:\n",
        "    #     torch.nn.init.kaiming_uniform_(m.weight, nonlinearity=\"relu\")\n",
        "    #     m.bias.data.fill_(0.1)\n",
        "    if type(m) == nn.Linear:\n",
        "        # apply a uniform distribution to the weights and a bias=0\n",
        "        torch.nn.init.kaiming_uniform_(m.weight, nonlinearity=\"relu\")\n",
        "        m.bias.data.fill_(0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvblKxZ8Ni-c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PretrainedModel(nn.Module):\n",
        "    def __init__(self, output_features):\n",
        "        super().__init__()\n",
        "        model = torchvision.models.resnet18(pretrained=True)\n",
        "        num_ftrs = model.fc.in_features\n",
        "        model.fc = nn.Sequential(\n",
        "            nn.Linear(num_ftrs, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.Linear(256, output_features),\n",
        "            nn.Softmax(dim=1),\n",
        "        )\n",
        "\n",
        "        self.model = model\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "\n",
        "model = PretrainedModel(output_features=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ka92MGFwPgFs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Freeze model\n",
        "freezer = skorch.callbacks.Freezer(lambda x: not x.startswith('model.fc'))\n",
        "\n",
        "lr_scheduler = skorch.callbacks.LRScheduler(policy=torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
        "                                            factor=0.1,\n",
        "                                            patience=3,\n",
        "                                            monitor='valid_loss')\n",
        "\n",
        "early_stopping = skorch.callbacks.EarlyStopping(patience=5)\n",
        "\n",
        "checkpoint_dir = './tmp'\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "# Checkpoint\n",
        "cp = skorch.callbacks.Checkpoint(dirname=checkpoint_dir)\n",
        "# Restore best checkpoint at end of training\n",
        "train_end_cp = skorch.callbacks.TrainEndCheckpoint(dirname=checkpoint_dir)\n",
        "\n",
        "lr = 0.01\n",
        "batch_size = 32\n",
        "max_epochs = 20\n",
        "\n",
        "net = skorch.NeuralNetClassifier(\n",
        "    model,\n",
        "    batch_size=batch_size,\n",
        "    max_epochs=max_epochs,\n",
        "    lr=lr,\n",
        "    train_split=train_split,\n",
        "    # Shuffle training data on each epoch\n",
        "    iterator_train__shuffle=True,\n",
        "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
        "    # skorch automatically applies logarithm so we have softmax at the end of our model\n",
        "    criterion=nn.modules.loss.NLLLoss,\n",
        "    optimizer=optim.Adam,\n",
        "    callbacks=[freezer, lr_scheduler, early_stopping, cp, train_end_cp])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9Uxbi5GJvvK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "91b9d3d8-9526-40a9-ef41-ffc6ec8fe383"
      },
      "source": [
        "import image_slicer\n",
        "image_slicer.slice ('/content/drive/My Drive/images nettoyées et labelisées (bis)/bateau/image2391.jpg', 2)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<Tile #1 - image2391_01_01.png>, <Tile #2 - image2391_01_02.png>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOlGheqwXtYE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26b7tAj1UlHW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "outputId": "7f4ba900-2f57-4521-9e78-66bb3b38387b"
      },
      "source": [
        "import shutil\n",
        "import image_slicer\n",
        "from PIL import ImageDraw, ImageFont\n",
        "for i in os.scandir('/content/drive/My Drive/DATASET FINAL/images nettoyées et labelisées (bis)/bateau'):\n",
        "    image_slicer.slice (i, 2)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-7da9623a9275>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshutil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mimage_slicer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImageDraw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImageFont\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/DATASET FINAL/images nettoyées et labelisées (bis)/bateau'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mimage_slicer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'image_slicer'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XgmpHpdWHSG",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjLQq3q8Krn-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "outputId": "e53a7edb-fe40-4f5f-85b8-20c8ace79899"
      },
      "source": [
        "!pip install image_slicer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting image_slicer\n",
            "  Downloading https://files.pythonhosted.org/packages/c8/aa/fcda7889ea0b248310b1cc67b98a7f398b38e0ea672eb95b17cbfd5d06b6/image_slicer-2.1.1-py2.py3-none-any.whl\n",
            "Collecting Pillow==7.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/bf/92385b4262178ca22b34f82e0e09c2922eb351fe39f3cc7b8ba9ea555b41/Pillow-7.2.0-cp36-cp36m-manylinux1_x86_64.whl (2.2MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2MB 16.5MB/s \n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Pillow, image-slicer\n",
            "  Found existing installation: Pillow 7.0.0\n",
            "    Uninstalling Pillow-7.0.0:\n",
            "      Successfully uninstalled Pillow-7.0.0\n",
            "Successfully installed Pillow-7.2.0 image-slicer-2.1.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoUw0FO6YK_2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "7fc370fe-0b15-4034-b89e-449711b07715"
      },
      "source": [
        "unfold1[2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'chat'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhaUBcn_VmLx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "bca61a5c-02b7-45e8-d97c-3fba8c6b6b6e"
      },
      "source": [
        "path = '/content/drive/My Drive/DATASET FINAL'\n",
        "folder = os.listdir (path)\n",
        "folder[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'images_finales'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2m4xwOg4EndL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "25132599-8b89-432b-d85d-afaf8e8e8080"
      },
      "source": [
        "import glob, os\n",
        "import image_slicer\n",
        "tiles = image_slicer.slice ('/content/drive/My Drive/renard_slice/images_boucle.jfif', 2, save=False)\n",
        "image_slicer.save_tiles(tiles, directory='/content/drive/My Drive/pont_slice',\\\n",
        "                            prefix='slice', format='png')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<Tile #1 - slice_01_01.png>, <Tile #2 - slice_01_02.png>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FQgzNoHiEaT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "outputId": "8cbfe39e-ae60-409b-9c2f-e400e2ebbdf6"
      },
      "source": [
        "import os\n",
        "import mimetypes\n",
        "import cv2\n",
        "maison_slice = '/content/drive/My Drive/maison_slice'\n",
        "\n",
        "ununfold1 = \"/content/drive/My Drive/DATASET FINAL/images nettoyées et labelisées (bis)/maison\"\n",
        "img_bat = os.listdir(ununfold1)\n",
        "for a in img_bat:\n",
        "    if os.path.isfile(ununfold1+'/'+a) and '.' in a and a.split('.')[-1] == 'png':\n",
        "        cv2.imwrite('.png', maison_slice )\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-131bb97389e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimg_bat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mununfold1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'.'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'png'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaison_slice\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: Expected Ptr<cv::UMat> for argument '%s'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADbPV80OjAJv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3eaf604f-6e05-406b-d3d5-3fe85d3a702a"
      },
      "source": [
        "mimetypes.guess_extension('.png', strict=True) \n",
        "img"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['image45_01_01.png',\n",
              " 'image45_01_02.png',\n",
              " 'image46_01_01.png',\n",
              " 'image46_01_02.png',\n",
              " 'image47_01_01.png',\n",
              " 'image47_01_02.png',\n",
              " 'image48_01_01.png',\n",
              " 'image48_01_02.png',\n",
              " 'image49_01_01.png',\n",
              " 'image49_01_02.png',\n",
              " 'image50_01_01.png',\n",
              " 'image50_01_02.png',\n",
              " 'image51_01_01.png',\n",
              " 'image51_01_02.png',\n",
              " 'image52_01_01.png',\n",
              " 'image52_01_02.png',\n",
              " 'image53_01_01.png',\n",
              " 'image53_01_02.png',\n",
              " 'image54_01_01.png',\n",
              " 'image54_01_02.png',\n",
              " 'image55_01_01.png',\n",
              " 'image55_01_02.png',\n",
              " 'image56_01_01.png',\n",
              " 'image56_01_02.png',\n",
              " 'image57_01_01.png',\n",
              " 'image57_01_02.png',\n",
              " 'image58_01_01.png',\n",
              " 'image58_01_02.png',\n",
              " 'image59_01_01.png',\n",
              " 'image59_01_02.png',\n",
              " 'image61_01_01.png',\n",
              " 'image61_01_02.png',\n",
              " 'image60_01_01.png',\n",
              " 'image60_01_02.png',\n",
              " 'image62_01_01.png',\n",
              " 'image62_01_02.png',\n",
              " 'image63_01_01.png',\n",
              " 'image63_01_02.png',\n",
              " 'image64_01_01.png',\n",
              " 'image64_01_02.png',\n",
              " 'image65_01_01.png',\n",
              " 'image65_01_02.png',\n",
              " 'image68_01_01.png',\n",
              " 'image68_01_02.png',\n",
              " 'image66_01_01.png',\n",
              " 'image66_01_02.png',\n",
              " 'image67_01_01.png',\n",
              " 'image67_01_02.png',\n",
              " 'image70_01_01.png',\n",
              " 'image70_01_02.png',\n",
              " 'image69_01_01.png',\n",
              " 'image69_01_02.png',\n",
              " 'image71_01_01.png',\n",
              " 'image71_01_02.png',\n",
              " 'image74_01_01.png',\n",
              " 'image74_01_02.png',\n",
              " 'image75_01_01.png',\n",
              " 'image75_01_02.png',\n",
              " 'image76_01_01.png',\n",
              " 'image76_01_02.png',\n",
              " 'image79_01_01.png',\n",
              " 'image79_01_02.png',\n",
              " 'image80_01_01.png',\n",
              " 'image80_01_02.png',\n",
              " 'image84_01_01.png',\n",
              " 'image84_01_02.png',\n",
              " 'image85_01_01.png',\n",
              " 'image85_01_02.png',\n",
              " 'image123_01_01.png',\n",
              " 'image123_01_02.png',\n",
              " 'image124_01_01.png',\n",
              " 'image124_01_02.png',\n",
              " 'image125_01_01.png',\n",
              " 'image125_01_02.png',\n",
              " 'image132_01_01.png',\n",
              " 'image132_01_02.png',\n",
              " 'image133_01_01.png',\n",
              " 'image133_01_02.png',\n",
              " 'image134_01_01.png',\n",
              " 'image134_01_02.png',\n",
              " 'image135_01_01.png',\n",
              " 'image135_01_02.png',\n",
              " 'image138_01_01.png',\n",
              " 'image138_01_02.png',\n",
              " 'image139_01_01.png',\n",
              " 'image139_01_02.png',\n",
              " 'image140_01_01.png',\n",
              " 'image140_01_02.png',\n",
              " 'image148_01_01.png',\n",
              " 'image148_01_02.png',\n",
              " 'image149_01_01.png',\n",
              " 'image149_01_02.png',\n",
              " 'image150_01_01.png',\n",
              " 'image150_01_02.png',\n",
              " 'image153_01_01.png',\n",
              " 'image153_01_02.png',\n",
              " 'image157_01_01.png',\n",
              " 'image157_01_02.png',\n",
              " 'image158_01_01.png',\n",
              " 'image158_01_02.png',\n",
              " 'image159_01_01.png',\n",
              " 'image159_01_02.png',\n",
              " 'image161_01_01.png',\n",
              " 'image161_01_02.png',\n",
              " 'image160_01_01.png',\n",
              " 'image160_01_02.png',\n",
              " 'image165_01_01.png',\n",
              " 'image165_01_02.png',\n",
              " 'image164_01_01.png',\n",
              " 'image164_01_02.png',\n",
              " 'image166_01_01.png',\n",
              " 'image166_01_02.png',\n",
              " 'image167_01_01.png',\n",
              " 'image167_01_02.png',\n",
              " 'image168_01_01.png',\n",
              " 'image168_01_02.png',\n",
              " 'image169_01_01.png',\n",
              " 'image169_01_02.png',\n",
              " 'image170_01_01.png',\n",
              " 'image170_01_02.png',\n",
              " 'image171_01_01.png',\n",
              " 'image171_01_02.png',\n",
              " 'image172_01_01.png',\n",
              " 'image172_01_02.png',\n",
              " 'image173_01_01.png',\n",
              " 'image173_01_02.png',\n",
              " 'image174_01_01.png',\n",
              " 'image174_01_02.png',\n",
              " 'image175_01_01.png',\n",
              " 'image175_01_02.png',\n",
              " 'image176_01_01.png',\n",
              " 'image176_01_02.png',\n",
              " 'image177_01_01.png',\n",
              " 'image177_01_02.png',\n",
              " 'image178_01_01.png',\n",
              " 'image178_01_02.png',\n",
              " 'image179_01_01.png',\n",
              " 'image179_01_02.png',\n",
              " 'image180_01_01.png',\n",
              " 'image180_01_02.png',\n",
              " 'image181_01_01.png',\n",
              " 'image181_01_02.png',\n",
              " 'image182_01_01.png',\n",
              " 'image182_01_02.png',\n",
              " 'image183_01_01.png',\n",
              " 'image183_01_02.png',\n",
              " 'image184_01_01.png',\n",
              " 'image184_01_02.png',\n",
              " 'image185_01_01.png',\n",
              " 'image185_01_02.png',\n",
              " 'image186_01_01.png',\n",
              " 'image186_01_02.png',\n",
              " 'image187_01_01.png',\n",
              " 'image187_01_02.png',\n",
              " 'image189_01_01.png',\n",
              " 'image189_01_02.png',\n",
              " 'image188_01_01.png',\n",
              " 'image188_01_02.png',\n",
              " 'image190_01_01.png',\n",
              " 'image190_01_02.png',\n",
              " 'image191_01_01.png',\n",
              " 'image191_01_02.png',\n",
              " 'image192_01_01.png',\n",
              " 'image192_01_02.png',\n",
              " 'image193_01_01.png',\n",
              " 'image193_01_02.png',\n",
              " 'image194_01_01.png',\n",
              " 'image194_01_02.png',\n",
              " 'image196_01_01.png',\n",
              " 'image196_01_02.png',\n",
              " 'image195_01_01.png',\n",
              " 'image195_01_02.png',\n",
              " 'image198_01_01.png',\n",
              " 'image198_01_02.png',\n",
              " 'image197_01_01.png',\n",
              " 'image197_01_02.png',\n",
              " 'image199_01_01.png',\n",
              " 'image199_01_02.png',\n",
              " 'image200_01_01.png',\n",
              " 'image200_01_02.png',\n",
              " 'image201_01_01.png',\n",
              " 'image201_01_02.png',\n",
              " 'image203_01_01.png',\n",
              " 'image203_01_02.png',\n",
              " 'image202_01_01.png',\n",
              " 'image202_01_02.png',\n",
              " 'image206_01_01.png',\n",
              " 'image206_01_02.png',\n",
              " 'image205_01_01.png',\n",
              " 'image205_01_02.png',\n",
              " 'image204_01_01.png',\n",
              " 'image204_01_02.png',\n",
              " 'image208_01_01.png',\n",
              " 'image208_01_02.png',\n",
              " 'image207_01_01.png',\n",
              " 'image207_01_02.png',\n",
              " 'image210_01_01.png',\n",
              " 'image210_01_02.png',\n",
              " 'image209_01_01.png',\n",
              " 'image209_01_02.png',\n",
              " 'image211_01_01.png',\n",
              " 'image211_01_02.png',\n",
              " 'image212_01_01.png',\n",
              " 'image212_01_02.png',\n",
              " 'image213_01_01.png',\n",
              " 'image213_01_02.png',\n",
              " 'image557_01_01.png',\n",
              " 'image557_01_02.png',\n",
              " 'image558_01_01.png',\n",
              " 'image558_01_02.png',\n",
              " 'image559_01_01.png',\n",
              " 'image559_01_02.png',\n",
              " 'image560_01_01.png',\n",
              " 'image560_01_02.png',\n",
              " 'image562_01_01.png',\n",
              " 'image562_01_02.png',\n",
              " 'image561_01_01.png',\n",
              " 'image561_01_02.png',\n",
              " 'image564_01_01.png',\n",
              " 'image564_01_02.png',\n",
              " 'image563_01_01.png',\n",
              " 'image563_01_02.png',\n",
              " 'image565_01_01.png',\n",
              " 'image565_01_02.png',\n",
              " 'image566_01_01.png',\n",
              " 'image566_01_02.png',\n",
              " 'image567_01_01.png',\n",
              " 'image567_01_02.png',\n",
              " 'image568_01_01.png',\n",
              " 'image568_01_02.png',\n",
              " 'image569_01_01.png',\n",
              " 'image569_01_02.png',\n",
              " 'image570_01_01.png',\n",
              " 'image570_01_02.png',\n",
              " 'image571_01_01.png',\n",
              " 'image571_01_02.png',\n",
              " 'image573_01_01.png',\n",
              " 'image573_01_02.png',\n",
              " 'image572_01_01.png',\n",
              " 'image572_01_02.png',\n",
              " 'image575_01_01.png',\n",
              " 'image575_01_02.png',\n",
              " 'image574_01_01.png',\n",
              " 'image574_01_02.png',\n",
              " 'image576_01_01.png',\n",
              " 'image576_01_02.png',\n",
              " 'image577_01_01.png',\n",
              " 'image577_01_02.png',\n",
              " 'image578_01_01.png',\n",
              " 'image578_01_02.png',\n",
              " 'image579_01_01.png',\n",
              " 'image579_01_02.png',\n",
              " 'image580_01_01.png',\n",
              " 'image580_01_02.png',\n",
              " 'image581_01_01.png',\n",
              " 'image581_01_02.png',\n",
              " 'image583_01_01.png',\n",
              " 'image583_01_02.png',\n",
              " 'image582_01_01.png',\n",
              " 'image582_01_02.png',\n",
              " 'image584_01_01.png',\n",
              " 'image584_01_02.png',\n",
              " 'image585_01_01.png',\n",
              " 'image585_01_02.png',\n",
              " 'image586_01_01.png',\n",
              " 'image586_01_02.png',\n",
              " 'image587_01_01.png',\n",
              " 'image587_01_02.png',\n",
              " 'image588_01_01.png',\n",
              " 'image588_01_02.png',\n",
              " 'image589_01_01.png',\n",
              " 'image589_01_02.png',\n",
              " 'image590_01_01.png',\n",
              " 'image590_01_02.png',\n",
              " 'image591_01_01.png',\n",
              " 'image591_01_02.png',\n",
              " 'image592_01_01.png',\n",
              " 'image592_01_02.png',\n",
              " 'image593_01_01.png',\n",
              " 'image593_01_02.png',\n",
              " 'image594_01_01.png',\n",
              " 'image594_01_02.png',\n",
              " 'image595_01_01.png',\n",
              " 'image595_01_02.png',\n",
              " 'image596_01_01.png',\n",
              " 'image596_01_02.png',\n",
              " 'image597_01_01.png',\n",
              " 'image597_01_02.png',\n",
              " 'image598_01_01.png',\n",
              " 'image598_01_02.png',\n",
              " 'image599_01_01.png',\n",
              " 'image599_01_02.png',\n",
              " 'image600_01_01.png',\n",
              " 'image600_01_02.png',\n",
              " 'image601_01_01.png',\n",
              " 'image601_01_02.png',\n",
              " 'image602_01_01.png',\n",
              " 'image602_01_02.png',\n",
              " 'image603_01_01.png',\n",
              " 'image603_01_02.png',\n",
              " 'image604_01_01.png',\n",
              " 'image604_01_02.png',\n",
              " 'image605_01_01.png',\n",
              " 'image605_01_02.png',\n",
              " 'image606_01_01.png',\n",
              " 'image606_01_02.png',\n",
              " 'image607_01_01.png',\n",
              " 'image607_01_02.png',\n",
              " 'image608_01_01.png',\n",
              " 'image608_01_02.png',\n",
              " 'image610_01_01.png',\n",
              " 'image610_01_02.png',\n",
              " 'image609_01_01.png',\n",
              " 'image609_01_02.png',\n",
              " 'image611_01_01.png',\n",
              " 'image611_01_02.png',\n",
              " 'image612_01_01.png',\n",
              " 'image612_01_02.png',\n",
              " 'image613_01_01.png',\n",
              " 'image613_01_02.png',\n",
              " 'image614_01_01.png',\n",
              " 'image614_01_02.png',\n",
              " 'image616_01_01.png',\n",
              " 'image616_01_02.png',\n",
              " 'image615_01_01.png',\n",
              " 'image615_01_02.png',\n",
              " 'image618_01_01.png',\n",
              " 'image618_01_02.png',\n",
              " 'image617_01_01.png',\n",
              " 'image617_01_02.png',\n",
              " 'image2278_01_01.png',\n",
              " 'image2278_01_02.png',\n",
              " 'image2280_01_01.png',\n",
              " 'image2280_01_02.png',\n",
              " 'image2279_01_01.png',\n",
              " 'image2279_01_02.png',\n",
              " 'image2282_01_01.png',\n",
              " 'image2282_01_02.png',\n",
              " 'image2281_01_01.png',\n",
              " 'image2281_01_02.png',\n",
              " 'image2283_01_01.png',\n",
              " 'image2283_01_02.png',\n",
              " 'image2284_01_01.png',\n",
              " 'image2284_01_02.png',\n",
              " 'image2285_01_01.png',\n",
              " 'image2285_01_02.png',\n",
              " 'image2286_01_01.png',\n",
              " 'image2286_01_02.png',\n",
              " 'image2287_01_01.png',\n",
              " 'image2287_01_02.png',\n",
              " 'image2288_01_01.png',\n",
              " 'image2288_01_02.png',\n",
              " 'image2289_01_01.png',\n",
              " 'image2289_01_02.png',\n",
              " 'image2290_01_01.png',\n",
              " 'image2290_01_02.png',\n",
              " 'image2291_01_01.png',\n",
              " 'image2291_01_02.png',\n",
              " 'image2292_01_01.png',\n",
              " 'image2292_01_02.png',\n",
              " 'image2293_01_01.png',\n",
              " 'image2293_01_02.png',\n",
              " 'image2294_01_01.png',\n",
              " 'image2294_01_02.png',\n",
              " 'image2296_01_01.png',\n",
              " 'image2296_01_02.png',\n",
              " 'image2295_01_01.png',\n",
              " 'image2295_01_02.png',\n",
              " 'image2297_01_01.png',\n",
              " 'image2297_01_02.png',\n",
              " 'image2298_01_01.png',\n",
              " 'image2298_01_02.png',\n",
              " 'image2299_01_01.png',\n",
              " 'image2299_01_02.png',\n",
              " 'image2301_01_01.png',\n",
              " 'image2301_01_02.png',\n",
              " 'image2300_01_01.png',\n",
              " 'image2300_01_02.png',\n",
              " 'image2303_01_01.png',\n",
              " 'image2303_01_02.png',\n",
              " 'image2302_01_01.png',\n",
              " 'image2302_01_02.png',\n",
              " 'image2304_01_01.png',\n",
              " 'image2304_01_02.png',\n",
              " 'image2305_01_01.png',\n",
              " 'image2305_01_02.png',\n",
              " 'image2306_01_01.png',\n",
              " 'image2306_01_02.png',\n",
              " 'image2307_01_01.png',\n",
              " 'image2307_01_02.png',\n",
              " 'image2308_01_01.png',\n",
              " 'image2308_01_02.png',\n",
              " 'image2309_01_01.png',\n",
              " 'image2309_01_02.png',\n",
              " 'image2310_01_01.png',\n",
              " 'image2310_01_02.png',\n",
              " 'image2311_01_01.png',\n",
              " 'image2311_01_02.png',\n",
              " 'image2312_01_01.png',\n",
              " 'image2312_01_02.png',\n",
              " 'image2313_01_01.png',\n",
              " 'image2313_01_02.png',\n",
              " 'image2314_01_01.png',\n",
              " 'image2314_01_02.png',\n",
              " 'image2315_01_01.png',\n",
              " 'image2315_01_02.png',\n",
              " 'image2316_01_01.png',\n",
              " 'image2316_01_02.png',\n",
              " 'image2317_01_01.png',\n",
              " 'image2317_01_02.png',\n",
              " 'image2319_01_01.png',\n",
              " 'image2319_01_02.png',\n",
              " 'image2318_01_01.png',\n",
              " 'image2318_01_02.png',\n",
              " 'image2323_01_01.png',\n",
              " 'image2323_01_02.png',\n",
              " 'image2324_01_01.png',\n",
              " 'image2324_01_02.png',\n",
              " 'image2326_01_01.png',\n",
              " 'image2326_01_02.png',\n",
              " 'image2325_01_01.png',\n",
              " 'image2325_01_02.png',\n",
              " 'image2327_01_01.png',\n",
              " 'image2327_01_02.png',\n",
              " 'image2328_01_01.png',\n",
              " 'image2328_01_02.png',\n",
              " 'image2330_01_01.png',\n",
              " 'image2330_01_02.png',\n",
              " 'image2329_01_01.png',\n",
              " 'image2329_01_02.png',\n",
              " 'image2331_01_01.png',\n",
              " 'image2331_01_02.png',\n",
              " 'image2332_01_01.png',\n",
              " 'image2332_01_02.png',\n",
              " 'image2333_01_01.png',\n",
              " 'image2333_01_02.png',\n",
              " 'image2334_01_01.png',\n",
              " 'image2334_01_02.png',\n",
              " 'image2335_01_01.png',\n",
              " 'image2335_01_02.png',\n",
              " 'image2336_01_01.png',\n",
              " 'image2336_01_02.png',\n",
              " 'image2337_01_01.png',\n",
              " 'image2337_01_02.png',\n",
              " 'image2338_01_01.png',\n",
              " 'image2338_01_02.png',\n",
              " 'image2339_01_01.png',\n",
              " 'image2339_01_02.png',\n",
              " 'image2340_01_01.png',\n",
              " 'image2340_01_02.png',\n",
              " 'image2341_01_01.png',\n",
              " 'image2341_01_02.png',\n",
              " 'image2342_01_01.png',\n",
              " 'image2342_01_02.png',\n",
              " 'image2343_01_01.png',\n",
              " 'image2343_01_02.png']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzF4twDAMVc2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7045f710-aa80-438d-c3d9-b5f363ca4123"
      },
      "source": [
        "print (listFolder[0])\n",
        "import glob, os\n",
        "import image_slicer\n",
        "#os.chdir(\"./\")\n",
        "#for file in glob.glob(\"/content/drive/My Drive/DATASET FINAL/[iG]*.jpg\"):\n",
        "   #\"\" h=image_slicer.slice(file, 2)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "images nettoyées et labelisées (bis)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liSbJcipAOL2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "7372510d-40f7-4655-8ba5-9616fb70b736"
      },
      "source": [
        "test = os.listdir('/content/drive/My Drive/DATASET FINAL/Groupe 2')\n",
        "test[0]\n",
        "my_drive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/My Drive'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_4af4hUK5k2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1QawvSRaP4x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 775
        },
        "outputId": "27939254-50fa-48ba-9215-973693087cab"
      },
      "source": [
        "#code pour parcourir les dossier, vérifier s'il on des zip et ouvrir\n",
        "#et couper les image et les envoyer vers les dossier cibles\n",
        "import  os\n",
        "#import image_slicer\n",
        "import zipfile\n",
        "'''\n",
        "#/content/drive/My Drive/DATASET FINAL/images nettoyées et labelisées (bis)\n",
        "#liste_essai = []\n",
        "rootPath='/content/drive/My Drive/'\n",
        "path = rootPath + 'DATASET FINAL'  #chemin d'accés au dossier contenant les img\n",
        "folder = os.listdir (path)   #list des sous dossiers de data set\n",
        "path_coupe = '/content/drive/My Drive/image coupe'\n",
        "j=0\n",
        "\n",
        "#vérifie si y a un document est zipé dans le dosier principal et si oui, l'ouvre dans ce dossier\n",
        "if os.path.isfile(rootPath+'/'+folder[j]) and '.' in folder[j] and folder[j].split('.')[-1] == 'zip' : \n",
        "    with zipfile.ZipFile(j,\"r\") as zip_ref:\n",
        "      zip_ref.extractall('/content/drive/My Drive/DATASET FINAL/')\n",
        "while j<len(folder) : \n",
        "#for j in folder : \n",
        "\n",
        "    pathFold1 = path + '/'+folder[j]\n",
        "    # chemin accés du sous dossier de data set numero j, ex 'image nettoyées ....'\n",
        "    listUnfold1 = os.listdir(pathFold1)  # list des sous dossier d'un des sous dossier de data set\n",
        "    \n",
        "    print(j, \": ouverture du dossier \", folder[j], \". il contient \", len(listUnfold1), \" dossiers\")\n",
        "    lock=0\n",
        "    #verifie si dans l'un des sous-dossier il y a un document zip, si oui l'ouvre dans le dossier principal\n",
        "    for zip_file in listUnfold1 : \n",
        "      zip_path = pathFold1+'/'+zip_file\n",
        "      if os.path.isfile(zip_path) and '.' in zip_path and zip_path.split('.')[-1] == 'zip' :\n",
        "        with zipfile.ZipFile(zip_path,\"r\") as zip_ref:\n",
        "          zip_ref.extractall('/content/drive/My Drive/DATASET FINAL/')\n",
        "         \n",
        "  \n",
        "    i= 0\n",
        "    for unfold2 in listUnfold1 :\n",
        "      pathUnfold2 = pathFold1 + '/'+ unfold2 # chemin accés au sous sous dossier, ex bateau\n",
        "      \n",
        "      if  os.path.isfile(pathUnfold2) and '.' in pathUnfold2 and pathUnfold2.split('.')[-1] == 'zip' :\n",
        "        break\n",
        "      else : \n",
        "        \n",
        "       \n",
        "        listImgToSlice = os.listdir(pathUnfold2)\n",
        "        # liste des images d'un sous sous dossiers (tel que bateau) à couper\n",
        "        print(unfold2 , \" possede \", len(listImgToSlice), \" éléments.\")\n",
        "\n",
        "        i=0\n",
        "        for img in listImgToSlice : \n",
        "          if os.path.isfile(pathUnfold2+'/'+img) and '.' in img and img.split('.')[-1] == 'jpg':\n",
        "            #liste_essai.append(img)\n",
        "            #i+=1\n",
        "    #j+=1\n",
        "    \n",
        "            path_crea = '/content/drive/My Drive/image coupe'+'/'+i+'_slice'\n",
        "  #       \n",
        "            if not os.path.exists(path_crea):\n",
        "             os.makedirs(path_crea)\n",
        "             tiles = image_slicer.slice (pathUnfold2+'/'+img, 2, save=False) \n",
        "              image_slicer.save_tiles(tiles, directory= path_coupe +'/' + unfold2.lower()+'_slice', prefix='sliced_'+ img.split(\".\")[0], format='png')\n",
        "              i+=1\n",
        "        \n",
        "            else:\n",
        "            \n",
        "              tiles = image_slicer.slice (pathUnfold2+'/'+img, 2, save=False) \n",
        "              image_slicer.save_tiles(tiles, directory= path_coupe +'/' + unfold2.lower()+'_slice', prefix='sliced_'+ img.split(\".\")[0], format='png')\n",
        "              i+=1\n",
        "            # print(unfold2, \"/\" , img, + i)\n",
        "          print(unfold2 , \" est terminé, on passe au suivant\")\n",
        "    j+=1\n",
        "    '''\n",
        "    '''\n",
        "  -'-'-'-\n",
        "  while i < len(unfold1)-1 : \n",
        "    ununfold1 = fold1 + '/'+ unfold1[i]  # chemin d'accés au sous sous dossier, ex bateau\n",
        "\n",
        "    img_for_slice = os.listdir(ununfold1) # liste des images d'un sous sous dossiers (tel que bateau)\n",
        "    for img in img_for_slice : \n",
        "      if os.path.isfile(ununfold1+'/'+img) and '.' in img and img.split('.')[-1] == 'jpg':\n",
        "      tiles = image_slicer.slice (ununfold1+'/'+img, 2, save=False) #/content/ .... /bateau/imageBateau.jpg\n",
        "      image_slicer.save_tiles(tiles, directory='/content/drive/My Drive/'+ unfold1[i].lower()+'_slice', prefix='slice', format='png')\n",
        "        #if os.path.isfile(ununfold1+'/'+img) and '.' in img and img.split('.')[-1] == 'png':\n",
        "    #print(ununfold1)\n",
        "    i+=1\n",
        "    '''\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 : ouverture du dossier  images nettoyées et labelisées (bis) . il contient  12  dossiers\n",
            "maison  possede  684  éléments.\n",
            "cygne  possede  215  éléments.\n",
            "chat  possede  279  éléments.\n",
            "pont  possede  277  éléments.\n",
            "tortue  possede  126  éléments.\n",
            "montagne  possede  244  éléments.\n",
            "bol  possede  249  éléments.\n",
            "lapin  possede  162  éléments.\n",
            "renard  possede  390  éléments.\n",
            "marteau  possede  147  éléments.\n",
            "coeur  possede  141  éléments.\n",
            "bateau  possede  368  éléments.\n",
            "1 : ouverture du dossier  images_finales . il contient  12  dossiers\n",
            "lapin  possede  3449  éléments.\n",
            "cygne  possede  2587  éléments.\n",
            "chat  possede  3160  éléments.\n",
            "bol  possede  2580  éléments.\n",
            "bateau  possede  3013  éléments.\n",
            "maison  possede  8451  éléments.\n",
            "marteau  possede  1837  éléments.\n",
            "montagne  possede  1144  éléments.\n",
            "pont  possede  2486  éléments.\n",
            "renard  possede  8421  éléments.\n",
            "tortue  possede  2652  éléments.\n",
            "coeur  possede  1925  éléments.\n",
            "2 : ouverture du dossier  Groupe 2 . il contient  3  dossiers\n",
            "3 : ouverture du dossier  .ipynb_checkpoints . il contient  0  dossiers\n",
            "4 : ouverture du dossier  Dataset_exploradomme . il contient  12  dossiers\n",
            "Bateau  possede  656  éléments.\n",
            "Renard  possede  575  éléments.\n",
            "Bol  possede  143  éléments.\n",
            "Tortue  possede  443  éléments.\n",
            "Lapin  possede  199  éléments.\n",
            "Chat  possede  1109  éléments.\n",
            "Pont  possede  402  éléments.\n",
            "Coeur  possede  109  éléments.\n",
            "Marteau  possede  271  éléments.\n",
            "Montagne  possede  203  éléments.\n",
            "Maison  possede  256  éléments.\n",
            "Cygne  possede  199  éléments.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WrXroRRB9x3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "888a411a-2e72-4925-8171-7fd1dd98f109"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "199"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_I03C1v710Fk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "outputId": "fe51e449-6c80-4459-e1f4-a9a4051529b9"
      },
      "source": [
        "import glob, os\n",
        "import image_slicer\n",
        "'''\n",
        "#/content/drive/My Drive/DATASET FINAL/images nettoyées et labelisées (bis)\n",
        "rootPath='/content/drive/My Drive/'\n",
        "path = rootPath + 'DATASET FINAL'  #chemin d'accés au dossier contenant les img\n",
        "folder = os.listdir (path)   #list des sous dossiers de data set\n",
        "path_coupe = '/content/drive/My Drive/image coupe'\n",
        "j=0\n",
        " \n",
        "pathFold1 = '/content/drive/My Drive/DATASET FINAL/images_finales' # chemin accés du sous dossier de data set numero j, ex 'image nettoyées ....'\n",
        "listUnfold1 = os.listdir(pathFold1)  # list des sous dossier d'un des sous dossier de data set\n",
        "print(j, \": ouverture du dossier \", pathFold1, \". il contient \", len(listUnfold1), \" dossiers\")\n",
        "\n",
        "i= 0\n",
        "for unfold2 in listUnfold1 :\n",
        "  pathUnfold2 = pathFold1 + '/'+ unfold2.lower() # chemin accés au sous sous dossier, ex bateau\n",
        "  listImgToSlice = os.listdir(pathUnfold2) # liste des images d'un sous sous dossiers (tel que bateau) à couper\n",
        "  print(unfold2 , \" possede \", len(listImgToSlice), \" éléments.\")\n",
        "\n",
        "  i=0\n",
        "  for img in listImgToSlice : \n",
        "    if os.path.isfile(pathUnfold2+'/'+img) and '.' in img and img.split('.')[-1] == 'jpg':\n",
        "      tiles = image_slicer.slice (pathUnfold2+'/'+img, 2, save=False) \n",
        "      image_slicer.save_tiles(tiles, directory= path_coupe +'/' + unfold2.lower()+'_slice', prefix='sliced_'+ img.split(\".\")[0], format='png')\n",
        "      i+=1\n",
        "    # print(unfold2, \"/\" , img, + i)\n",
        "  print(unfold2 , \" est terminé, on passe au suivant\")\n",
        "  '''\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 : ouverture du dossier  /content/drive/My Drive/DATASET FINAL/images_finales . il contient  12  dossiers\n",
            "lapin  possede  383  éléments.\n",
            "lapin  est terminé, on passe au suivant\n",
            "cygne  possede  32  éléments.\n",
            "cygne  est terminé, on passe au suivant\n",
            "chat  possede  395  éléments.\n",
            "chat  est terminé, on passe au suivant\n",
            "bol  possede  117  éléments.\n",
            "bol  est terminé, on passe au suivant\n",
            "bateau  possede  3013  éléments.\n",
            "bateau  est terminé, on passe au suivant\n",
            "maison  possede  939  éléments.\n",
            "maison  est terminé, on passe au suivant\n",
            "marteau  possede  167  éléments.\n",
            "marteau  est terminé, on passe au suivant\n",
            "montagne  possede  104  éléments.\n",
            "montagne  est terminé, on passe au suivant\n",
            "pont  possede  226  éléments.\n",
            "pont  est terminé, on passe au suivant\n",
            "renard  possede  1203  éléments.\n",
            "renard  est terminé, on passe au suivant\n",
            "tortue  possede  204  éléments.\n",
            "tortue  est terminé, on passe au suivant\n",
            "coeur  possede  66  éléments.\n",
            "coeur  est terminé, on passe au suivant\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rsfbb-_z324V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        },
        "outputId": "32c2c4bd-06b2-4a69-b41a-9159febfe9c9"
      },
      "source": [
        "'''\n",
        "#pour deziper un dossier a part et couper ses images\n",
        "import os\n",
        "import image_slicer\n",
        "import zipfile\n",
        "#with zipfile.ZipFile(\"/content/drive/My Drive/DATASET FINAL/Groupe 2/Dataset_exploradomme-20200903T143013Z-001.zip\",\"r\") as zip_ref:\n",
        "  #  zip_ref.extractall(\"/content/drive/My Drive/DATASET FINAL/Groupe 2/Dataset_exploradomme\")\n",
        "\n",
        "pathFold1 = '/content/drive/My Drive/DATASET FINAL/Groupe 2/Dataset_exploradomme/Dataset_exploradomme' # chemin accés du sous dossier de data set numero j, ex 'image nettoyées ....'\n",
        "listUnfold1 = os.listdir(pathFold1)  # list des sous dossier d'un des sous dossier de data set\n",
        "print( \": ouverture du dossier \", pathFold1, \". il contient \", len(listUnfold1), \" dossiers\")\n",
        "path_coupe = '/content/drive/My Drive/image coupe'\n",
        "i= 0\n",
        "for unfold2 in listUnfold1 :\n",
        "  pathUnfold2 = pathFold1 + '/'+ unfold2 # chemin accés au sous sous dossier, ex bateau\n",
        "  listImgToSlice = os.listdir(pathUnfold2) # liste des images d'un sous sous dossiers (tel que bateau) à couper\n",
        "  print(unfold2 , \" possede \", len(listImgToSlice), \" éléments.\")\n",
        "\n",
        "  i=0\n",
        "  for img in listImgToSlice : \n",
        "    if os.path.isfile(pathUnfold2+'/'+img) and '.' in img and img.split('.')[-1] == 'jpg':\n",
        "      tiles = image_slicer.slice (pathUnfold2+'/'+img, 2, save=False) \n",
        "      image_slicer.save_tiles(tiles, directory= path_coupe +'/' + unfold2.lower()+'_slice', prefix='sliced_'+ img.split(\".\")[0], format='png')\n",
        "      i+=1\n",
        "    # print(unfold2, \"/\" , img, + i)\n",
        "  print(unfold2 , \" est terminé, on passe au suivant\")\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ": ouverture du dossier  /content/drive/My Drive/DATASET FINAL/Groupe 2/Dataset_exploradomme/Dataset_exploradomme . il contient  12  dossiers\n",
            "Bateau  possede  656  éléments.\n",
            "Bateau  est terminé, on passe au suivant\n",
            "Renard  possede  575  éléments.\n",
            "Renard  est terminé, on passe au suivant\n",
            "Bol  possede  143  éléments.\n",
            "Bol  est terminé, on passe au suivant\n",
            "Tortue  possede  443  éléments.\n",
            "Tortue  est terminé, on passe au suivant\n",
            "Lapin  possede  199  éléments.\n",
            "Lapin  est terminé, on passe au suivant\n",
            "Chat  possede  1109  éléments.\n",
            "Chat  est terminé, on passe au suivant\n",
            "Pont  possede  402  éléments.\n",
            "Pont  est terminé, on passe au suivant\n",
            "Coeur  possede  109  éléments.\n",
            "Coeur  est terminé, on passe au suivant\n",
            "Marteau  possede  271  éléments.\n",
            "Marteau  est terminé, on passe au suivant\n",
            "Montagne  possede  203  éléments.\n",
            "Montagne  est terminé, on passe au suivant\n",
            "Maison  possede  256  éléments.\n",
            "Maison  est terminé, on passe au suivant\n",
            "Cygne  possede  199  éléments.\n",
            "Cygne  est terminé, on passe au suivant\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XIpDvulEQG9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyZcMO1jyJrj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "outputId": "ab51d282-50ea-4497-dfdc-055afeb60660"
      },
      "source": [
        "#netoyage des dossier poluer\n",
        "import os, shutil           \n",
        "directory_name = os.listdir('/content/drive/My Drive/') #seul élément du code à modifier pour vider le fichier\n",
        "for i in directory_name : \n",
        "  if os.path.isfile(directory_name+'/'+img) and '.' in img and img.split('.')[-1] == 'png':\n",
        "    os.remove(i)\n",
        "    \n",
        "    #path_maison = '/content/drive/My Drive/' + i +'_slice'\n",
        "  #list_img_maison = shutil.rmtree('/content/drive/My Drive/image coupé/')\n",
        "  #path_crea = '/content/drive/My Drive/image coupe'+'/'+i+'_slice'\n",
        "  #os.mkdir(path_crea)\n",
        "\n",
        "'''\n",
        "#à utiliser pour vider tout les dossires avec 'slice' dans le nom\n",
        "pathRoot = '/content/drive/My Drive/'\n",
        "listDirSlice = os.listdir(pathRoot)\n",
        "for dir in listDirSlice : \n",
        "  if dir.split(\"_\")[1]==\"slice\" :\n",
        "    list_img_maison = shutil.rmtree(pathRoot + dir)\n",
        "    os.mkdir(path_maison)\n",
        "'''\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-a7d1b6e08424>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdirectory_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#seul élément du code à modifier pour vider le fichier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdirectory_name\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'.'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'png'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: can only concatenate list (not \"str\") to list"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YaKJkQk2I28N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in directory_name :\n",
        "  path_crea = '/content/drive/My Drive/image coupé'+'/'+i+'_slice'\n",
        "  os.mkdir(path_crea)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPq3fxlutOhK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 518
        },
        "outputId": "802d4291-08a4-46a8-8c41-5f1f55eaec32"
      },
      "source": [
        "import glob, os\n",
        "import image_slicer\n",
        "#/content/drive/My Drive/DATASET FINAL/images nettoyées et labelisées (bis)\n",
        "#path = '/content/drive/My Drive/DATASET FINAL'\n",
        "#folder = os.listdir (path)\n",
        "\n",
        "#fold1 = path + '/'+folder[0]\n",
        "#unfold1 = os.listdir(fold1)\n",
        "\n",
        "#ununfold1 = fold1 + '/'+ unfold1[1]\n",
        "#img_bat = os.listdir(ununfold1)\n",
        "#for i in img_bat : \n",
        "  # img = image_slicer.slice (ununfold1+'/'+i, 2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['maison', 'cygne', 'chat', 'pont', 'tortue', 'montagne', 'bol', 'lapin', 'renard', 'marteau', 'coeur', 'models', 'bateau']\n",
            "/content/drive/My Drive/DATASET FINAL/images nettoyées et labelisées (bis)/maison\n",
            "/content/drive/My Drive/DATASET FINAL/images nettoyées et labelisées (bis)/cygne\n",
            "/content/drive/My Drive/DATASET FINAL/images nettoyées et labelisées (bis)/chat\n",
            "/content/drive/My Drive/DATASET FINAL/images nettoyées et labelisées (bis)/pont\n",
            "/content/drive/My Drive/DATASET FINAL/images nettoyées et labelisées (bis)/tortue\n",
            "/content/drive/My Drive/DATASET FINAL/images nettoyées et labelisées (bis)/montagne\n",
            "/content/drive/My Drive/DATASET FINAL/images nettoyées et labelisées (bis)/bol\n",
            "/content/drive/My Drive/DATASET FINAL/images nettoyées et labelisées (bis)/lapin\n",
            "/content/drive/My Drive/DATASET FINAL/images nettoyées et labelisées (bis)/renard\n",
            "/content/drive/My Drive/DATASET FINAL/images nettoyées et labelisées (bis)/marteau\n",
            "/content/drive/My Drive/DATASET FINAL/images nettoyées et labelisées (bis)/coeur\n",
            "/content/drive/My Drive/DATASET FINAL/images nettoyées et labelisées (bis)/models\n",
            "['lapin', 'cygne', 'chat', 'bol', 'bateau', 'maison', 'marteau', 'montagne', 'pont', 'renard', 'tortue', 'coeur']\n",
            "/content/drive/My Drive/DATASET FINAL/images_finales/lapin\n",
            "/content/drive/My Drive/DATASET FINAL/images_finales/cygne\n",
            "/content/drive/My Drive/DATASET FINAL/images_finales/chat\n",
            "/content/drive/My Drive/DATASET FINAL/images_finales/bol\n",
            "/content/drive/My Drive/DATASET FINAL/images_finales/bateau\n",
            "/content/drive/My Drive/DATASET FINAL/images_finales/maison\n",
            "/content/drive/My Drive/DATASET FINAL/images_finales/marteau\n",
            "/content/drive/My Drive/DATASET FINAL/images_finales/montagne\n",
            "/content/drive/My Drive/DATASET FINAL/images_finales/pont\n",
            "/content/drive/My Drive/DATASET FINAL/images_finales/renard\n",
            "/content/drive/My Drive/DATASET FINAL/images_finales/tortue\n",
            "/content/drive/My Drive/DATASET FINAL/images_finales/coeur\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6V6cHJ-UOgZx",
        "colab_type": "text"
      },
      "source": [
        "##DATA augmentation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9pYYi_0PDpl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "3f7d8f29-d68d-4229-c771-941d453d5c99"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from matplotlib.pyplot import imread, imshow, subplots, show\n",
        "\n",
        "\n",
        " \n",
        "\n",
        "def plot(data_generator):\n",
        "\n",
        "  data_generator.fit(images)\n",
        "\n",
        "  image_iterator = data_generator.flow(images)\n",
        "\n",
        "  \n",
        "\n",
        "  fig, rows = subplots(nrows = 1, ncols = 4, figsize = (18,18))\n",
        "\n",
        "  for row in rows:\n",
        "\n",
        "    row.imshow(image_iterator.next()[0].astype(‘int’))\n",
        "\n",
        "    row.axis(‘off’)\n",
        "\n",
        "\n",
        " \n",
        "\n",
        "    images = os.listidr('/content/drive/My Drive/image coupe/marteau_slice')\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "    imshow(images[0])\n",
        "\n",
        "    show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-34-ed4288c35dc7>\"\u001b[0;36m, line \u001b[0;32m20\u001b[0m\n\u001b[0;31m    row.imshow(image_iterator.next()[0].astype(‘int’))\u001b[0m\n\u001b[0m                                                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character in identifier\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDD43MixQoyR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "outputId": "a22b5b83-0153-44a5-b374-f9e12de902fc"
      },
      "source": [
        "!pip install imgaug"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: imgaug in /usr/local/lib/python3.6/dist-packages (0.2.9)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from imgaug) (7.0.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from imgaug) (1.18.5)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.6/dist-packages (from imgaug) (1.7.1)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.6/dist-packages (from imgaug) (2.4.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from imgaug) (1.4.1)\n",
            "Requirement already satisfied: scikit-image>=0.11.0 in /usr/local/lib/python3.6/dist-packages (from imgaug) (0.16.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from imgaug) (1.15.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from imgaug) (3.2.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from imgaug) (4.1.2.30)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug) (1.1.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug) (2.5)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug) (2.4.7)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image>=0.11.0->imgaug) (4.4.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEqCtZYCOdDp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "outputId": "7241d10d-ce6b-4c11-8554-9654b688258d"
      },
      "source": [
        "   \n",
        "\n",
        "\n",
        "\n",
        "import os\n",
        "\n",
        "import imageio\n",
        "\n",
        "import imgaug as ia\n",
        "\n",
        "import imgaug.augmenters as iaa\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "import matplotlib\n",
        "\n",
        "%matplotlib inline\n",
        "heart_path = '/content/drive/My Drive/image coupe/coeur_slice'\n",
        "\n",
        "img_heart = os.listdir('/content/drive/My Drive/image coupe/coeur_slice')\n",
        "list_img = []\n",
        "\n",
        "for image in img_heart: \n",
        "  list_img.append(image)\n",
        "for i in list_img : \n",
        "  \n",
        "  ia.imshow(i)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\t\n",
        "#Rotating\n",
        "\n",
        "\n",
        "  rotate=iaa.Affine(rotate=(-50, 30))\n",
        "\n",
        "  rotated_image=rotate.augment_image(image)\n",
        "\n",
        "  ia.imshow(rotated_image)\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        " \t\n",
        "Adding noise\n",
        "\n",
        " \n",
        "gaussian_noise=iaa.AdditiveGaussianNoise(10,20)\n",
        "\n",
        "noise_image=gaussian_noise.augment_image(image)\n",
        "\n",
        "ia.imshow(noise_image)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\t\n",
        "Flipping horizontally\n",
        "\n",
        "\n",
        "flip_hr=iaa.Fliplr(p=1.0)\n",
        "\n",
        "flip_hr_image= flip_hr.augment_image(image)\n",
        "\n",
        "ia.imshow(flip_hr_image)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\t\n",
        "Flipping vertically\n",
        "\n",
        "\n",
        "flip_vr=iaa.Flipud(p=1.0)\n",
        "\n",
        "flip_vr_image= flip_vr.augment_image(image)\n",
        "\n",
        "ia.imshow(flip_vr_image)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\t\n",
        "Changing the brightness\n",
        "\n",
        "\n",
        "image = …\n",
        "\n",
        "contrast=iaa.GammaContrast(gamma=2.0)\n",
        "\n",
        "contrast_image =contrast.augment_image(image)\n",
        "\n",
        "ia.imshow(contrast_image)\n",
        "'''\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-a945983ff5ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist_img\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m   \u001b[0mia\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/imgaug/imgaug.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(image, backend)\u001b[0m\n\u001b[1;32m   1840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1841\u001b[0m         \u001b[0mdpi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m96\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1842\u001b[0;31m         \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdpi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdpi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1843\u001b[0m         \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# if the figure is too narrow, the footer may appear and make the fig suddenly wider (ugly)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1844\u001b[0m         \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'shape'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VQAP9hlqeJF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "outputId": "f1362d1c-4ed8-461a-fe9c-7794801505dc"
      },
      "source": [
        " \n",
        "\n",
        "import shutil\n",
        "import os\n",
        "import numpy as np\n",
        "import argparse\n",
        "from filecmp import dircmp\n",
        "import filecmp\n",
        "import time #a suppr quand script OK\n",
        "def get_files_from_folder(path):\n",
        "    files = os.listdir(path)\n",
        "    return list(files)\n",
        "def main(path_to_data, path_to_train_data, path_to_test_data, train_ratio):\n",
        "    # get dirs\n",
        "    _, dirs, _ = next(os.walk(path_to_data))\n",
        "    #print(dirs) # return list class\n",
        "    # calculates how many train data per class\n",
        "    data_counter_per_class = np.zeros((len(dirs)))\n",
        "    #print(data_counter_per_class) #retourne les classes à 0\n",
        "    lst_total = []\n",
        "    for i in range(len(dirs)):\n",
        "        path = os.path.join(path_to_data, dirs[i])\n",
        "        files = get_files_from_folder(path)\n",
        "        lst_total.append(files)\n",
        "        data_counter_per_class[i] = len(lst_total[i])\n",
        "        test_counter = np.round(data_counter_per_class * (1 - train_ratio))\n",
        "    # transfers files\n",
        "    for i in range(len(dirs)):\n",
        "        path_to_original = os.path.join(path_to_data, dirs[i])\n",
        "        path_to_train = os.path.join(path_to_train_data, dirs[i])\n",
        "        path_to_save = os.path.join(path_to_test_data, dirs[i])\n",
        "\n",
        "        #creates dir\n",
        "        if not os.path.exists(path_to_save):\n",
        "            os.makedirs(path_to_save)\n",
        "            files = get_files_from_folder(path_to_original)\n",
        "        for j in range(int(test_counter[i])):\n",
        "            dst = os.path.join(path_to_save, files[j])\n",
        "            src = os.path.join(path_to_original, files[j])\n",
        "            shutil.copy(src, dst)\n",
        "        if not os.path.exists(path_to_train):\n",
        "            os.makedirs(path_to_train)\n",
        "            files = get_files_from_folder(path_to_original)\n",
        "        d1_contents = set(os.listdir(path_to_original))\n",
        "        d2_contents = set(os.listdir(path_to_save))\n",
        "        common = list(d1_contents & d2_contents)\n",
        "        common_files = [f\n",
        "                        for f in common\n",
        "                        if os.path.isfile(os.path.join(path_to_original, f))\n",
        "                        ]\n",
        "        delta = filecmp.dircmp(path_to_original,\n",
        "                            path_to_save, ignore=common_files)\n",
        "        for i in range(len(delta.left_list)):\n",
        "            dst1 = os.path.join(path_to_train, delta.left_list[i])\n",
        "            src1 = os.path.join(path_to_original, delta.left_list[i])\n",
        "            shutil.copy(src1, dst1)\n",
        "\n",
        "def parse_args():\n",
        "  parser = argparse.ArgumentParser(description=\"Dataset divider\")\n",
        "  parser.add_argument(\"--data_path\", required=True,\n",
        "    help=\"Path to data\")\n",
        "  parser.add_argument(\"--train_data_path_to_save\", required=True,\n",
        "    help=\"Path to train data where to save\")\n",
        "  parser.add_argument(\"--test_data_path_to_save\", required=True,\n",
        "    help=\"Path to test data where to save\")\n",
        "  parser.add_argument(\"--train_ratio\", required=True,\n",
        "    help=\"Train ratio - 0.7 means splitting data in 70 % train and 30 % test\")\n",
        "  return parser.parse_args()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  args = parse_args()\n",
        "  main(args.data_path, args.train_data_path_to_save, args.test_data_path_to_save, float(args.train_ratio))\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "usage: ipykernel_launcher.py [-h] --data_path DATA_PATH\n",
            "                             --train_data_path_to_save TRAIN_DATA_PATH_TO_SAVE\n",
            "                             --test_data_path_to_save TEST_DATA_PATH_TO_SAVE\n",
            "                             --train_ratio TRAIN_RATIO\n",
            "ipykernel_launcher.py: error: the following arguments are required: --data_path, --train_data_path_to_save, --test_data_path_to_save, --train_ratio\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2h_kowf_HT2R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import Augmentor\n",
        "p = Augmentor.Pipeline(\"/content/drive/My Drive/image coupe\")\n",
        "p.rotate(probability=0.7, max_left_rotation=10, max_right_rotation=10)\n",
        "p.zoom(probability=0.5, min_factor=1.1, max_factor=1.5)\n",
        "p.sample(3)\n",
        "p.process()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OanCW9CpV_rk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtNp1zlDQ_Wt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "9ec909f3-c5d2-4c8b-c1c5-6bb811a1cbe0"
      },
      "source": [
        "pip install Augmentor\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting Augmentor\n",
            "  Downloading https://files.pythonhosted.org/packages/cb/79/861f38d5830cff631e30e33b127076bfef8ac98171e51daa06df0118c75f/Augmentor-0.2.8-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tqdm>=4.9.0 in /usr/local/lib/python3.6/dist-packages (from Augmentor) (4.41.1)\n",
            "Requirement already satisfied: Pillow>=5.2.0 in /usr/local/lib/python3.6/dist-packages (from Augmentor) (7.0.0)\n",
            "Requirement already satisfied: future>=0.16.0 in /usr/local/lib/python3.6/dist-packages (from Augmentor) (0.16.0)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from Augmentor) (1.18.5)\n",
            "Installing collected packages: Augmentor\n",
            "Successfully installed Augmentor-0.2.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zgCltRy7OJq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tj2MCevwuJGz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "np.random.seed(42)\n",
        "data = ImageDataBunch.from_folder(path, train=\".\", valid_pct=0.2,\n",
        "        ds_tfms=get_transforms(), size=224, num_workers=4).normalize(imagenet_stats)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KeiE1aC8wf47",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "#import image_slicer\n",
        "import zipfile\n",
        "with zipfile.ZipFile(\"/content/drive/My Drive/DATASET FINAL/Groupe 2/Dataset_exploradomme-20200903T143013Z-001.zip\",\"r\") as zip_ref:\n",
        "    zip_ref.extractall(\"/content/drive/My Drive/DATASET FINAL/\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrk_4BBMLtF3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "1ceb21ed-1de4-4944-cc4a-1b1fa2dce084"
      },
      "source": [
        "import Augmentor\n",
        "p = Augmentor.Pipeline(\"/content/drive/My Drive/image coupe/\")\n",
        "p.rotate(probability=0.7, max_left_rotation=10, max_right_rotation=10)\n",
        "p.zoom(probability=0.3, min_factor=1.1, max_factor=1.6)\n",
        "p.skew_tilt(probability=0.7, magnitude=0.3)\n",
        "p.skew_left_right(probability=0.7, magnitude=0.3)\n",
        "p.skew_top_bottom(probability=0.7, magnitude=0.3)\n",
        "p.sample(3)\n",
        "p.process()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rExecuting Pipeline:   0%|          | 0/3 [00:00<?, ? Samples/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Initialised with 14700 image(s) found.\n",
            "Output directory set to /content/drive/My Drive/image coupe/output."
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing <PIL.Image.Image image mode=RGB size=960x1080 at 0x7F57715C1390>: 100%|██████████| 3/3 [00:01<00:00,  1.85 Samples/s]\n",
            "Processing <PIL.Image.Image image mode=RGB size=960x1080 at 0x7F576A49CD68>: 100%|██████████| 14700/14700 [1:52:18<00:00,  2.18 Samples/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hkmLLUaVdqU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "outputId": "868dba04-a8da-4c82-8bf0-be2b9fbcc68f"
      },
      "source": [
        "import Augmentor\n",
        "check = \"/content/drive/My Drive/image coupe/\"\n",
        "list_check = os.listdir(check)\n",
        "for dossier in list_check: \n",
        "  if len(os.listdir(check+dossier)) < 800 : \n",
        "   p = Augmentor.Pipeline(check+dossier+'/')\n",
        "   p.rotate(probability=0.7, max_left_rotation=10, max_right_rotation=10)\n",
        "   p.zoom(probability=0.5, min_factor=1.1, max_factor=1.5)\n",
        "   p.sample(400)\n",
        "   p.process()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initialised with 0 image(s) found.\n",
            "Output directory set to /content/drive/My Drive/image coupe/models/output."
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-a17731d6dcf3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m    \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobability\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_left_rotation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_right_rotation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m    \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzoom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobability\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m    \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m    \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/Augmentor/Pipeline.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, n, multi_threaded)\u001b[0m\n\u001b[1;32m    346\u001b[0m         \"\"\"\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maugmentor_images\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m             raise IndexError(\"There are no images in the pipeline. \"\n\u001b[0m\u001b[1;32m    349\u001b[0m                              \u001b[0;34m\"Add a directory using add_directory(), \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m                              \"pointing it to a directory containing images.\")\n",
            "\u001b[0;31mIndexError\u001b[0m: There are no images in the pipeline. Add a directory using add_directory(), pointing it to a directory containing images."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0bNrLw3Vj7X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "181dfc7d-42ce-481c-894b-b9940ea77048"
      },
      "source": [
        "!pip install Augmentor"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting Augmentor\n",
            "  Downloading https://files.pythonhosted.org/packages/cb/79/861f38d5830cff631e30e33b127076bfef8ac98171e51daa06df0118c75f/Augmentor-0.2.8-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from Augmentor) (1.18.5)\n",
            "Requirement already satisfied: Pillow>=5.2.0 in /usr/local/lib/python3.6/dist-packages (from Augmentor) (7.0.0)\n",
            "Requirement already satisfied: tqdm>=4.9.0 in /usr/local/lib/python3.6/dist-packages (from Augmentor) (4.41.1)\n",
            "Requirement already satisfied: future>=0.16.0 in /usr/local/lib/python3.6/dist-packages (from Augmentor) (0.16.0)\n",
            "Installing collected packages: Augmentor\n",
            "Successfully installed Augmentor-0.2.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgnDMHbRZz5L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "outputId": "791e317c-e831-47e0-a0a7-399c5b25a749"
      },
      "source": [
        "path_list = '/content/drive/My Drive/image coupe'\n",
        "liste= os.listdir(path_list)\n",
        "maison_slice = os.listdir('/content/drive/My Drive/image coupe/maison_slice')\n",
        "cygne_slice= '/content/drive/My Drive/image coupe/cygne_slice']\n",
        "chat_slice = ['/content/drive/My Drive/image coupe/chat_slice']\n",
        "pont_slice = ['/content/drive/My Drive/image coupe/pont_slice']\n",
        "tortue_slice =['/content/drive/My Drive/image coupe/tortue_slice']\n",
        "montagne_slice= ['/content/drive/My Drive/image coupe/montagne_slice']\n",
        "bol_slice=['/content/drive/My Drive/image coupe/bol_slice']\n",
        "lapin_slice =['/content/drive/My Drive/image coupe/lapin_slice']\n",
        "renard_slice=['/content/drive/My Drive/image coupe/renard_slice']\n",
        "marteau_slice=['/content/drive/My Drive/image coupe/marteau_slice']\n",
        "coeur_slice=['/content/drive/My Drive/image coupe/coeur_slice']\n",
        "bateau_slice=['/content/drive/My Drive/image coupe/bateau_slice']\n",
        "\n",
        "    \n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-f9514d68104a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0mpath3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mpic\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpath3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0;34m'k'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'append'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3NNEfu4FfrWT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "outputId": "791e317c-e831-47e0-a0a7-399c5b25a749"
      },
      "source": [
        "path_list = '/content/drive/My Drive/image coupe'\n",
        "liste= os.listdir(path_list)\n",
        "maison_slice = os.listdir('/content/drive/My Drive/image coupe/maison_slice')\n",
        "cygne_slice= ['/content/drive/My Drive/image coupe/cygne_slice']\n",
        "chat_slice = ['/content/drive/My Drive/image coupe/chat_slice']\n",
        "pont_slice = ['/content/drive/My Drive/image coupe/pont_slice']\n",
        "tortue_slice =['/content/drive/My Drive/image coupe/tortue_slice']\n",
        "montagne_slice= ['/content/drive/My Drive/image coupe/montagne_slice']\n",
        "bol_slice=['/content/drive/My Drive/image coupe/bol_slice']\n",
        "lapin_slice =['/content/drive/My Drive/image coupe/lapin_slice']\n",
        "renard_slice=['/content/drive/My Drive/image coupe/renard_slice']\n",
        "marteau_slice=['/content/drive/My Drive/image coupe/marteau_slice']\n",
        "coeur_slice=['/content/drive/My Drive/image coupe/coeur_slice']\n",
        "bateau_slice=['/content/drive/My Drive/image coupe/bateau_slice']\n",
        "\n",
        "    \n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-f9514d68104a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0mpath3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mpic\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpath3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0;34m'k'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'append'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-KZhbw4cftMO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "outputId": "791e317c-e831-47e0-a0a7-399c5b25a749"
      },
      "source": [
        "path_list = '/content/drive/My Drive/image coupe'\n",
        "liste= os.listdir(path_list)\n",
        "maison_slice = os.listdir('/content/drive/My Drive/image coupe/maison_slice')\n",
        "cygne_slice= ['/content/drive/My Drive/image coupe/cygne_slice']\n",
        "chat_slice = ['/content/drive/My Drive/image coupe/chat_slice']\n",
        "pont_slice = ['/content/drive/My Drive/image coupe/pont_slice']\n",
        "tortue_slice =['/content/drive/My Drive/image coupe/tortue_slice']\n",
        "montagne_slice= ['/content/drive/My Drive/image coupe/montagne_slice']\n",
        "bol_slice=['/content/drive/My Drive/image coupe/bol_slice']\n",
        "lapin_slice =['/content/drive/My Drive/image coupe/lapin_slice']\n",
        "renard_slice=['/content/drive/My Drive/image coupe/renard_slice']\n",
        "marteau_slice=['/content/drive/My Drive/image coupe/marteau_slice']\n",
        "coeur_slice=['/content/drive/My Drive/image coupe/coeur_slice']\n",
        "bateau_slice=['/content/drive/My Drive/image coupe/bateau_slice']\n",
        "\n",
        "    \n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-f9514d68104a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0mpath3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mpic\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpath3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0;34m'k'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'append'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NpEl6_4Vfuuf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "aa51059a-1463-4c17-a7cb-41327d070394"
      },
      "source": [
        "path_list = '/content/drive/My Drive/image coupe'\n",
        "liste= os.listdir(path_list)\n",
        "\n",
        "maison_slice = os.listdir('/content/drive/My Drive/image coupe/maison_slice')\n",
        "cygne_slice=os.listdir('/content/drive/My Drive/image coupe/cygne_slice')\n",
        "chat_slice = os.listdir('/content/drive/My Drive/image coupe/chat_slice')\n",
        "pont_slice = os.listdir('/content/drive/My Drive/image coupe/pont_slice')\n",
        "tortue_slice =os.listdir('/content/drive/My Drive/image coupe/tortue_slice')\n",
        "montagne_slice= os.listdir('/content/drive/My Drive/image coupe/montagne_slice')\n",
        "bol_slice=os.listdir('/content/drive/My Drive/image coupe/bol_slice')\n",
        "lapin_slice =os.listdir('/content/drive/My Drive/image coupe/lapin_slice')\n",
        "renard_slice=os.listdir('/content/drive/My Drive/image coupe/renard_slice')\n",
        "marteau_slice=os.listdir('/content/drive/My Drive/image coupe/marteau_slice')\n",
        "coeur_slice=os.listdir('/content/drive/My Drive/image coupe/coeur_slice')\n",
        "bateau_slice=os.listdir('/content/drive/My Drive/image coupe/bateau_slice')\n",
        "\n",
        "big_liste = [\n",
        "maison_slice,\n",
        "cygne_slice,\n",
        "chat_slice,\n",
        "pont_slice,\n",
        "tortue_slice,\n",
        "montagne_slice,\n",
        "bol_slice,\n",
        "lapin_slice,\n",
        "renard_slice,\n",
        "marteau_slice,\n",
        "coeur_slice,\n",
        "bateau_slice]\n",
        "\n",
        "maison_slice_sample = []\n",
        "cygne_slice_sample= []\n",
        "chat_slice_sample= []\n",
        "pont_slice_sample= []\n",
        "tortue_slice_sample= []\n",
        "montagne_slice_sample= []\n",
        "bol_slice_sample= []\n",
        "lapin_slice_sample= []\n",
        "renard_slice_sample= []\n",
        "marteau_slice_sample= []\n",
        "coeur_slice_sample= []\n",
        "bateau_slice_sample= []\n",
        "\n",
        "#Dico = {'img_mai': maison_slice, 'img_chat': chat_slice, 'img_pont': pont_slice, 'img_tor' : tortue_slice, img_bol: bol_slice,\n",
        "#img_cygne : cygne_slice, img_mont: montagne_slice, img_lap: lapin_slice, img_fox: renard_slice, img_coeur: coeur_slice, img_bateau : bateau_slice}\n",
        "\n",
        "if len(bateau_slice) >1000 : \n",
        "  bateau_slice_sample.append(sample(bateau_slice,800))\n",
        "else :\n",
        "   bateau_slice_sample.append(sample(bateau_slice,all)) \n",
        "if len(cygne_slice) >1000 : \n",
        "  cygne_slice_sample.append(sample(cygne_slice,800))\n",
        "else : \n",
        "  cygne_slice_sample.append(sample(cygne_slice,all))\n",
        "if len(maison_slice) >1000 : \n",
        "  maison_slice_sample.append(sample(maiso_slice,800))\n",
        "else : bateau_slice_sample.append(samaison_slice)\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-727cdedea4e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0mcygne_slice_sample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcygne_slice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m800\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m   \u001b[0mcygne_slice_sample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcygne_slice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaison_slice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m\u001b[0;36m1000\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m   \u001b[0mmaison_slice_sample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaiso_slice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m800\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/random.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, population, k)\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0mrandbelow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_randbelow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Sample larger than population or is negative\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: '<=' not supported between instances of 'int' and 'builtin_function_or_method'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4V6QVh5cahH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "maison_slice = []\n",
        "cygne_slice= []\n",
        "chat_slice =[]\n",
        "pont_slice = []\n",
        "tortue_slice =[]\n",
        "montagne_slice =[]\n",
        "bol_slice =[]\n",
        "lapin_slice = []\n",
        "renard_slice = []\n",
        "marteau_slice = []\n",
        "coeur_slice = []\n",
        "bateau_slice = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtOpCWTE_wwT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "outputId": "2e987dcb-0958-4c58-96af-9af41345cd15"
      },
      "source": [
        "%run /content/drive/My\\ Drive/main.py --data_path=/content/drive/My\\ Drive/image\\ coupe/ --train_data_path_to_save=/content/train/ --test_data_path_to_save=/content/test/ --train_ratio=0.7\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/content/drive/My Drive/main.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m   \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m   \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_data_path_to_save\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_data_path_to_save\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_ratio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/main.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(path_to_data, path_to_train_data, path_to_test_data, train_ratio)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_original\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/shutil.py\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0mdst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m     \u001b[0mcopyfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m     \u001b[0mcopymode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/shutil.py\u001b[0m in \u001b[0;36mcopyfile\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfsrc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                 \u001b[0mcopyfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfsrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/image coupe/maison_slice/sliced_frame7319_01_02.png'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJcVgTr87ACZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "38613af2-2d77-4615-c3a7-a8d28748f2bf"
      },
      "source": [
        "!python3 \"/content/drive/My Drive/main.py\" --data_path=\"/content/drive/My Drive/imagecoupe/\" --train_data_path_to_save=\"/content/train1/\" --test_data_path_to_save=\"/content/test1/\" --train_ratio=0.7"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/My Drive/main.py\", line 86, in <module>\n",
            "    main(args.data_path, args.train_data_path_to_save, args.test_data_path_to_save, float(args.train_ratio))\n",
            "  File \"/content/drive/My Drive/main.py\", line 18, in main\n",
            "    _, dirs, _ = next(os.walk(path_to_data))\n",
            "StopIteration\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lV9UEGhIH0w_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "efaf51ce-e3a4-4e9e-d289-08c7f4dbd443"
      },
      "source": [
        "import Augmentorp = Augmentor.Pipeline(\"/content/drive1/My Drive/image coupe/\")p.rotate(probability=0.7, max_left_rotation=10, max_right_rotation=10)p.zoom(probability=0.3, min_factor=1.1, max_factor=1.6)p.skew_tilt(probability=0.7, magnitude=0.3)p.skew_left_right(probability=0.7, magnitude=0.3)p.skew_top_bottom(probability=0.7, magnitude=0.3)p.sample(3)p.process()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileExistsError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-67-391aeec64159>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclasses_dir\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m   \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_dir\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m'/train'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m   \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_dir\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m'/val'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_dir\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m'/test'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m         \u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;31m# Cannot rely on checking for EEXIST, since the operating system\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: 'C:/Users/utilisateur/Downloads/imagecoupe_/train/bateau_slice'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmXC4jz81cKx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "outputId": "e2deff41-1197-478c-abef-a9ef83f67213"
      },
      "source": [
        "save_cygne = os.listdir('/content/drive/My Drive/image coupe/cygne_slice')\n",
        "os.remove('/content/drive/My Drive/image coupe/cygne_slice/.ipynb_checkpoints')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IsADirectoryError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-eef3d4c67d0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msave_cygne\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/image coupe/cygne_slice'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/image coupe/cygne_slice/.ipynb_checkpoints'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Is a directory: '/content/drive/My Drive/image coupe/cygne_slice/.ipynb_checkpoints'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0t_SJM-1cCF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f3babd1d-a61f-4881-82b4-ad554f7bb354"
      },
      "source": [
        "path_maison = '/content/drive/My Drive/image coupe/maison_slice'\n",
        "list_maison = os.listdir('/content/drive/My Drive/image coupe/maison_slice')\n",
        "for v in list_maison :\n",
        "   \n",
        "  if path_maison+\"/\"+v == a : \n",
        "    print('image existe')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "image existe\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWHMdCmmr-AY",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}